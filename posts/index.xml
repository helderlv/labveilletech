<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Posts on Labo Design &amp; Tech</title><link>https://helderlv.github.io/labveilletech/posts/</link><description>Recent content in Posts on Labo Design &amp; Tech</description><generator>Hugo</generator><language>fr-FR</language><lastBuildDate>Fri, 23 Jan 2026 14:11:00 +0100</lastBuildDate><atom:link href="https://helderlv.github.io/labveilletech/posts/index.xml" rel="self" type="application/rss+xml"/><item><title>Spatial Design : Quand l’interface sort de l’écran</title><link>https://helderlv.github.io/labveilletech/posts/article3/</link><pubDate>Fri, 23 Jan 2026 14:11:00 +0100</pubDate><guid>https://helderlv.github.io/labveilletech/posts/article3/</guid><description>&lt;h2 id="le-monde-réel-comme-bureau-infini"&gt;Le monde réel comme bureau infini&lt;/h2&gt;
&lt;p&gt;Le Spatial Design représente la nouvelle frontière du design numérique. Il remet en question notre manière de concevoir les interfaces. Avec l’arrivée du Spatial Computing, illustrée par des appareils comme l’Apple Vision Pro, l’écran traditionnel cède la place à une expérience immersive où les éléments numériques se superposent à notre environnement réel. L’espace autour de nous devient un immense bureau interactif.&lt;/p&gt;
&lt;p&gt;Autrement dit, on ne conçoit plus sur une surface plane mais dans l’espace, avec des volumes et des interactions à la fois intuitifs et confortables, sans tomber dans la complexité inutile.&lt;/p&gt;</description></item><item><title>Google A2UI : Le standard de l’interface générative</title><link>https://helderlv.github.io/labveilletech/posts/article2/</link><pubDate>Thu, 22 Jan 2026 10:30:00 +0100</pubDate><guid>https://helderlv.github.io/labveilletech/posts/article2/</guid><description>&lt;h2 id="la-fin-des-réponses-purement-textuelles"&gt;La fin des réponses purement textuelles&lt;/h2&gt;
&lt;p&gt;Le monde des chatbots et des assistants virtuels est sur le point de vivre une transformation majeure. Google a officiellement annoncé le lancement public d’A2UI (Agent to UI), un projet open source ambitieux conçu pour combler le fossé entre le texte et l&amp;rsquo;action visuelle.&lt;/p&gt;
&lt;p&gt;Publié le 15 décembre 2025 en version 0.8, ce protocole novateur vise à standardiser la manière dont les agents d&amp;rsquo;intelligence artificielle communiquent avec nos applications quotidiennes. Jusqu&amp;rsquo;à présent, lorsque nous posions une question complexe à une IA, elle nous répondait par des paragraphes de texte parfois difficiles à digérer. Avec A2UI, l&amp;rsquo;IA change de dimension car elle ne se contente plus de répondre avec des mots mais génère dynamiquement des éléments visuels interactifs.&lt;/p&gt;</description></item><item><title>Les Collections Étendues Figma</title><link>https://helderlv.github.io/labveilletech/posts/article1/</link><pubDate>Wed, 21 Jan 2026 11:17:41 +0100</pubDate><guid>https://helderlv.github.io/labveilletech/posts/article1/</guid><description>&lt;h2 id="de-quoi-sagit-il-"&gt;De quoi s&amp;rsquo;agit-il ?&lt;/h2&gt;
&lt;p&gt;Figma permet désormais de partager des variables comme des couleurs ou des espacements entre plusieurs fichiers différents. Auparavant, il fallait tout copier manuellement d&amp;rsquo;un fichier à l&amp;rsquo;autre, mais aujourd&amp;rsquo;hui on peut créer une bibliothèque principale qui diffuse ses réglages vers d&amp;rsquo;autres projets. C&amp;rsquo;est comme avoir un cerveau central qui contrôle l&amp;rsquo;apparence de plusieurs produits en même temps sans devoir tout dupliquer.&lt;/p&gt;
&lt;img src="../../images/Overridden variables.png" alt="Interface de gestion des variables dans Figma" style="max-width: 900px; width: 100%;"&gt;
&lt;p&gt;&lt;em&gt;Figure 1 : Interface de gestion des variables dans Figma, montrant des collections de couleurs et leurs valeurs pour différents modes.&lt;/em&gt;
&lt;br&gt;
&lt;em&gt;Source : &lt;a href="https://help.figma.com/hc/en-us/articles/36346281624471-Extend-a-variable-collection"&gt;Figma Help Center&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;</description></item><item><title>Se former à l'ère des LLM</title><link>https://helderlv.github.io/labveilletech/posts/article4/</link><pubDate>Sat, 17 Jan 2026 11:45:00 +0100</pubDate><guid>https://helderlv.github.io/labveilletech/posts/article4/</guid><description>&lt;p&gt;L&amp;rsquo;arrivée des LLM (Large Language Models) comme ChatGPT ou Claude a bouleversé l&amp;rsquo;accès à la connaissance. Dans mon parcours en UX/UI, j&amp;rsquo;ai théoriquement accès à un &amp;ldquo;mentor&amp;rdquo; virtuel disponible 24/7. Mais cette facilité cache un piège, confondre l&amp;rsquo;accès immédiat à l&amp;rsquo;information avec l&amp;rsquo;acquisition réelle de compétences durables.&lt;/p&gt;
&lt;p&gt;Comment utiliser ces outils pour accélérer mon apprentissage sans diminuer ma capacité à réfléchir ?&lt;/p&gt;
&lt;h2 id="1-le-problème--la-facilité-est-lennemie-de-la-mémoire"&gt;1. Le problème : La facilité est l&amp;rsquo;ennemie de la mémoire&lt;/h2&gt;
&lt;p&gt;Pour comprendre les risques de l&amp;rsquo;IA, il faut comprendre comment le cerveau apprend. Les sciences cognitives, et notamment les travaux du chercheur Robert Bjork, mettent en avant le concept de &amp;ldquo;difficulté désirable&amp;rdquo; (&lt;em&gt;Desirable Difficulty&lt;/em&gt;).&lt;/p&gt;</description></item><item><title>Mon système d'écoute</title><link>https://helderlv.github.io/labveilletech/posts/article5/</link><pubDate>Fri, 16 Jan 2026 11:20:00 +0100</pubDate><guid>https://helderlv.github.io/labveilletech/posts/article5/</guid><description>&lt;p&gt;Avoir une Taxonomie (des mots-clés) ne suffit pas. Pour qu&amp;rsquo;une veille soit efficace, il faut connecter ces mots-clés aux bonnes sources. Mon système d&amp;rsquo;écoute est conçu pour être multicanal, visuel et international.&lt;/p&gt;
&lt;p&gt;Voici comment j&amp;rsquo;organise mes flux d&amp;rsquo;information pour rester à jour sur le Design et la Technologie.&lt;/p&gt;
&lt;h2 id="1-le-format-vidéo--apprendre-par-lobservation"&gt;1. Le format vidéo : Apprendre par l&amp;rsquo;observation&lt;/h2&gt;
&lt;p&gt;Étant très visuel, je privilégie Youtube pour voir les designers en action. Ce n&amp;rsquo;est pas seulement de la théorie, c&amp;rsquo;est de la pratique en temps réel.&lt;/p&gt;</description></item></channel></rss>